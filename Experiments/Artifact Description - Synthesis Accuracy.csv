,,,,,
,,,Data Manipulation Queries,,
,No.,Query,Result,Accuracy from formatted query,NL Accuracy
,1,Get the multiplication results of columns X and Y from dataset Z.,"DotProduct(GetColumn(columnName(string(X)),file(string(A))),GetColumn(columnName(string(Y)),file(string(B))))",0,0
,2,"For input dataset1.csv, select columns representing performance metrics named “GPU cycles” and “memory utilization rates” about kernel named “function 1”, store the results into dataset1-filtered.csv",No result,0,0
,3,"Select  benchmark_name, gpu_type, execution_time from any dataset where:“Hardware” contains “GPU” “Software” contains “Benchmark”",No result,0,0
,4,Dataset information: return all the column names of this dataset.,GetColumnNames(file(string(cgo17-nvidia.csv))),1,1
,5,Get the dataset X from dataset Y without column ‘Memory Frequency’.,"GetDataset(file(string(Y)),file(string(X)),exception(string(Memory Frequency)))",1,1
,6,"Select X1,X2 from dataset A and Y1, Y2 from dataset B then merge them into dataset C",No result,0,0
,7,Get the normalized results for column X from dataset A.,"normalization(columnName(string(l1cache)),file(string(cgo17-nvidia.csv)))",1,1
,8,Get the encoding results for column X from dataset A.,"encodeData(columnName(string(l1cache)),file(string(cgo17-nvidia.csv)))",1,1
,9,Convert data file X to CSV format type.,convertJSON_to_CSV(file(string(X.json))),1,1
,10,Convert data file Y to JSON format type.,convertCSV_to_JSON(file(string(X.csv))),1,1
,11,"Get the merging results of columns X,Y,Z from dataset W.","mergeColumns(columnName(string(X,Y,Z)),file(string(w)))",1,1
,12,"Get count(*) of column X from dataset A, Group By ‘Model’.","countInstances(columnName(string(X)),file(string(Y)),groupBy(string(Model)))",1,1
,13,"Get count(*) of column X from dataset A, Group By ‘Model’ and ‘Bench Number’.","countInstances(columnName(string(X)),file(string(Y)),groupBy(string(Model,BenchNumber)))",1,1
,14,merge dataset X with dataset Y,"MergeDataset(file(string(X)), file(string(Y)))",1,1
,15,get encoding result for column X from file A with type one hot encoding,"encodeData2(columnName(string(l1cache)),file(string(cgo17-nvidia.csv)),type(string(oneHotEncoding)))",1,1
,16,Get all columns from dataset Y without column ‘Memory Frequency’.,"GetAllColumns(file(string(cgo17-nvidia.csv)),exception(string(MemoryFrequency)))",1,1
,17,Get all columns from dataset Y,GetAllColumns(file(string(cgo17-nvidia.csv))),1,1
,,,,,
,,,Ontology Related cases : Simple,,
,No.,Query,Result,Accuracy from formatted query,NL Accuracy
,1,get AI model that has model type  'prediction',"GetAIModel(modelName('decisionTree.onnx','randomForest.onnx','gradBoost.onnx','Case Study A.ipynb ','Case Study B.ipynb '))",1,1
,2,get AI model having model type 'prediction' and target machine named 'lassen',GetAIModel(modelName('decisionTree.onnx')),1,1
,3,get AI model having model type 'classification',"GetAIModel(modelName('GPU-runtime analysis','Gradient Decent Algorithm Implementation'))",1,1
,4,get ai model with model format 'python',GetAIModel(modelName('ED.py')),1,1
,5,list of  AI models with format 'python notebook',"GetAIModel(modelName('Case Study A.ipynb ','Case Study B.ipynb ','GPU-runtime analysis','Classification Analysis - SVM, Trees and Boosting','Gradient Decent Algorithm Implementation'))",1,1
,6,get AI model with version '1.2.1' and learning type 'Supervised',"GetAIModel(modelName('Case Study B.ipynb ','GPU-runtime analysis','Classification Analysis - SVM'))",1,1
,7,get AI model having learning type 'Supervised' and subject 'gradient decent',GetAIModel(modelName('Gradient Decent Algorithm Implementation')),1,0
,8,Get dataset with subject 'GPGPU',"GetDataset(datasetName('data_IBM_&_AWS_082020','lassen_overhead','performance_results_dataset','merged_data'))
",1,1
,9,get dataset having subject 'Heterogeneous System',"GetDataset(datasetName('cgo17-amd.csv','cgo17-nvidia.csv','kernels.tar.bz2','our-models.tar.bz2','our-predictions.tar.bz2','case-study-a-weights.tar.bz2','our-models-aa','our-models-ab','our-predictions.tar.bz2','pact-2014-oracles.csv','pact-2014-runtimes.csv'))
",1,1
,10,return dataset whose license is 'GPL-3.0',"GetDataset(datasetName('cgo17-amd.csv','cgo17-nvidia.csv','kernels.tar.bz2','our-models.tar.bz2','our-predictions.tar.bz2','case-study-a-weights.tar.bz2','our-models-aa','our-models-ab','our-predictions.tar.bz2','pact-2014-oracles.csv','pact-2014-runtimes.csv'))",1,1
,11,get dataset with version 0.2.0 and subject 'LLVM',"GetDataset(datasetName('llvm_ir_20.06.01.tar.bz2','graphs_20.06.01.tar.bz2','labels_reachability_20.06.01.tar.bz2','labels_domtree_20.06.01.tar.bz2','labels_datadep_20.06.01.tar.bz2','labels_liveness_20.06.01.tar.bz2','labels_subexpressions_20.06.01.tar.bz2','dataflow_logs_20.06.01.tar.bz2','vocab_20.06.01.tar.bz2'))
",1,1
,12,get dataset with name 'dataflow_logs_20.06.01.tar.bz2',"GetDataset(datasetName('dataflow_logs_20.06.01.tar.bz2'))
",1,1
,13,get project which is funded by 'Lawrence Livermore National Laboratory'',"GetProject(projectName('XPlacer: A framework for Guiding Optimal Use of GPU Unified Memory','Enhancing DataRaceBench for Evaluating Data Race Detection Tools'))
",1,1
,14,get project in program area 'OpenMP',"GetProject(projectName('Enhancing DataRaceBench for Evaluating Data Race Detection Tools','A Probabilistic Machine Learning Approachto Scheduling Parallel Loops With Bayesian Optimization'))
",1,1
,15,get project that is funded by 'ICT' in the program area of 'parallel computing',"GetProject(projectName('A Probabilistic Machine Learning Approachto Scheduling Parallel Loops With Bayesian Optimization'))
",1,1
,16,get person who is a member of 'Center for Applied Scientific Computing'',GetPerson(personName('Chunhua')),1,1
,17,"person having affiliation with 'Lawrence Livermore National Laboratory, CA'",GetPerson(personName('Lee')),1,1
,18,"""get a list of people who <hpc:contributor to a project named 'GPU kernal'>""",Query can not be handled,0,0
,19,"""get files having <hpc:contributor with hpc:givenName 'Lee'>""","file(datasetName(['data_IBM_&_AWS_082020']))
",1,1
,20,"""get files which are <hpc:contributor by hpc:givenName 'Lee'>""",file(datasetName(string())),0,0
,21,"""get dataset having <hpc:contributor by a person hpc:givenName 'chunhua'>""",file(datasetName(['data_IBM_&_AWS_082020'])),1,0
,22,"""get software having <hpc:version '16.2'> and <hpc:usedBy by project hpc:name 'X'>""","GetSoftware(softwareName(conditions(hpc:version '16.2'),conditions(hpc:usedBy by project hpc:name 'X')))",1,1
,23,"""give hardware <hpc:usedBy experiment hpc:name 'OPUM'>""",GetHardware(hardwareName(conditions(hpc:usedBy experiment hpc:name 'OPUM'))),1,1
,24,"""give hardware that was <hpc:usedBy experiment hpc:name 'OPUM'>""",GetHardware(hardwareName(conditions())),0,0
,25,get person having job title of 'Senior Computer Scientist' and whose gender is 'male',"GetPerson(personName('Chunhua'))
",1,1
,,,,,
,,,Ontology Related cases : Complex,,
,No.,Query,Result,Accuracy from formatted query,NL Accuracy
,1,get all columns from dataset named 'X',GetAllColumns(file(datasetName(conditions(hpc:name 'X')))),1,1
,2,Get memory related data from file 'cgo-nvidia.csv'.,"GetColumn(columnName(string(memLocal,memAtomic,wgSize,coalesced)), file(string(cgo17-nvidia.csv)))",1,1
,3,get cpu related columns from dataset named 'X',"GetColumn(columnName(string(""coprocessorSpeed,cpuFrequency"")),file(datasetName(conditions(""<hpc:name 'X'>""))))",1,1
,4,"get normalization results of columns 'X,Y' from file with name 'Z'","normalization(columnName(""X,Y""),file(datasetName(conditions(""<hpc:name 'Z'>""))))",1,1
,5,get all files having contributors with name 'Lee',"file(datasetName(conditions(""<hpc:contributor which has hpc:givenName 'Lee'>"")))",1,1
,6,get dataset generated by experiment named 'Optimal Unified Memory - Online Inference',"file(datasetName(conditions(""<hpc:generatedBy Experiment hpc:name 'Optimal Unified Memory - Online Inference'>"")))",1,1
,7,get software having version '16.2'  and is used by project named 'X',"GetSoftware(softwareName(conditions(""<hpc:version '16.2'>  <hpc:usedBy project hpc:name 'X'>"")))",1,1
,8,get hardware used by experiment named 'OPUM',"GetHardware(hardwareName(conditions(""<hpc:usedBy experiment hpc:name 'OPUM'>"")))
",1,1
,9,merge dataset 'X' and dataset having license 'Apache',"MergeDataset(file(datasetName(string(X))),file(datasetName(conditions(hpc:license 'Apache'))))",1,1
,10,convert file with contributor having name 'Caleb' to JSON,"convertCSV_to_JSON(file(datasetName(conditions(""<hpc:contributor having hpc:name 'caleb'>""))))",1,1
,11,"""list of AI models with <hpc:modelFormat 'python notebook'>""","GetAIModel(modelName(['Case Study A.ipynb ','Case Study B.ipynb ','GPU-runtime analysis','Classification Analysis - SVM, Trees and Boosting','Gradient Decent Algorithm Implementation']))",1,1
,12,"return all data columns from file ""X"" except ""P""'","encodeData(columnName(string(P)),file(datasetName(string(X))))",0,0
,13,"get data dealing with <schema:domainIncludes hpc:cpu> from file ""Y""'","GetColumn(columnName(conditions(schema:domainIncludes hpc:cpu)),file(datasetName(string(Y))))",1,1
,14,"extract data linked to <schema:domainIncludes hpc:cpu> from file ""X"" '","GetColumn(columnName(conditions(schema:domainIncludes hpc:cpu)),file(datasetName(string(X))))",1,0
,15,"“normalize the columns \""X,Y\"" from file <hpc:name 'Z'>""","normalization(columnName(string(X,Y)),file(datasetName(conditions(hpc:name 'Z'))))",1,1
,16,merge dataset 'X' with another dataset having <hpc:license 'Apache'>,Error!,0,0
,17,merge dataset 'X' with another dataset <hpc:license 'Apache'>,"MergeDataset(file(datasetName(string(X))),file(datasetName(conditions(hpc:license 'Apache'))))",1,1
,18,"""convert file having <hpc:contributor hpc:givenName 'caleb'> to json format""",convertCSV_to_JSON(file(datasetName(conditions(hpc:contributor hpc:givenName 'caleb')))),1,1
,,,,,
,,,,,
,,,,0.85,0.8
,,,,,
,,,Section ,From Correct Formatted Query,From NL query
,,,Data Manupulation queries,76.47%,76.47%
,,,Simple Ontology Interactive queries,88.00%,80.00%
,,,Combined Queries,88.89%,83.33%
,,,Without ontology,21.67%,21.67%
,,,Overall,85.00%,80.00%